{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence to Sequence modelling notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.initialize import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=width>\n",
    "\n",
    "### 1. Sequence to sequence modelling tasks\n",
    "\n",
    "Sequence to sequence modelling tasks are machine learning tasks where both the inputs and the outputs are sequences.\n",
    "\n",
    "Some examples:\n",
    "<p align=\"left\">\n",
    "<img src=\"resources/assets/seq_to_seq_applications.png\" alt=\"drawing\" width=\"800\" >\n",
    "</p>\n",
    "\n",
    "Let's first see some examples of sequence to sequence (seq2seq) modelling problems.\n",
    "</div>\n",
    "\n",
    "<div class=width>\n",
    "\n",
    "### Examples of sequence to sequence (seq2seq) tasks\n",
    "Let's look at some concrete seq2seq tasks for illustration. \n",
    "\n",
    "#### 1. Shift a sequence\n",
    "This is a toy example where we just shift a sequence to the right, and pad zeros on the left. For example, we may want to shift a input by three steps,\n",
    "$$\\begin{align*}\n",
    "\\text{Input:} & \\, 5,8,9,0,1,2,5,6 \\\\\n",
    "\\text{Output:} &\\,  0,0,0,5,8,9,0,1\n",
    "\\end{align*}$$\n",
    "Shifting inputs by $k $ units is actually a linear relation, equivalent to a convolution of the input with a delta impulse,\n",
    "$$\\begin{align*}\n",
    "y(t) = \\sum_s \\delta(s-k)x(t-s)\n",
    "\\end{align*}$$\n",
    "where \n",
    "$$\n",
    "\\delta(s-k) = \\begin{cases}\n",
    "                    1 & s = k \\\\\n",
    "                    0 & \\text{else}\n",
    "                \\end{cases}.\n",
    "$$\n",
    "\n",
    "This relationship is completely determined by the parameter $k$. It can also be considered as the memory of this relationship, because we have $y(t) = y(t-k)$. thus when $k$ is large, $y(t)$ will depend on a input value far from it.\n",
    " \n",
    "Theoretically, RNN does not perform well on this task while CNN may have very good performance. \n",
    ">(See our paper [Approximation Theory of Convolutional Architectures for Time Series Modelling](https://proceedings.mlr.press/v139/jiang21d.html))\n",
    "\n",
    "\n",
    "</div>\n",
    "\n",
    "<style>\n",
    "div.width {\n",
    "\n",
    "    margin:auto;\n",
    "    max-width: 1000px;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "352ea5a00d644a94bfe0a301d91a773c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(HBox(children=(HTML(value='&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'), Button(description=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ShiftPlotter(k=25).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=width>\n",
    "\n",
    "#### 2. Convolution of a sequence\n",
    "Convolution is one of the most basic operations that can be considered as sequence to sequence tasks.\n",
    "Suppose $\\boldsymbol\\rho$ is a convolution filter, then the convolution of the input $\\boldsymbol x$ with the filter is given by\n",
    "$$\\begin{align*}\n",
    "y(t) = \\boldsymbol\\rho \\ast\\boldsymbol x =\\sum_s \\rho(s)x(t-s).\n",
    "\\end{align*}$$\n",
    "In this case, the filter $\\boldsymbol \\rho$ determine the relationship.\n",
    "\n",
    "<div>\n",
    "\n",
    "<style>\n",
    "div.width {\n",
    "\n",
    "    margin:auto;\n",
    "    max-width: 1000px;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8999eed21a74bda93da16eec547c691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(HBox(children=(Text(value='0.002, 0.022, 0.097, 0.159, 0.097, 0.022, 0.002', des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ConvoPlotter().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=width>\n",
    "\n",
    "#### 3. Lorenz96 System\n",
    "\n",
    "Now let's look at a more complicated example where the input output relationship is determined by an nonlinear dynamical system.\n",
    "  \n",
    "  \n",
    "The system have $K$ inputs $\\{x_k\\}$, $K$ outputs $\\{y_k\\}$ and $JK$ hidden variables $\\{z_{j,k}\\}$ with $k = 1, 2, \\dots, K$ and $j = 1, 2, \\dots, J$.\n",
    "The parameters $K,J$ control the number of variables in the system, and can be viewed as a complexity measure.\n",
    "The system satisfies the following dynamics\n",
    "\\begin{align*}\n",
    "    \\frac{dy_k}{dt} & = -y_{k-1}(y_{k-2}-y_{k+1})-y_k + {\\color{green} x_k}  - \\frac{1}{J}\\sum_{j=1}^J z_{j,k},  \\\\\n",
    "    \\frac{dz_{j,k}}{dt} & = -z_{j+1,k}(z_{j+2,k}-z_{j-1,k})-z_{j,k} + y_k.\n",
    "\\end{align*}\n",
    "\n",
    "Thus, given a set of inputs $\\{x_k\\}$, the system determines a set of outputs $\\{y_k\\}$.\n",
    "The following plot shows an example with $K=1$, where we have one curve as input, and the system gives an output curve.\n",
    "<div>\n",
    "\n",
    "<style>\n",
    "div.width {\n",
    "\n",
    "    margin:auto;\n",
    "    max-width: 1000px;\n",
    "}\n",
    "</style>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7cf87f65e654a59b200e75c207a4c25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(HBox(children=(HTML(value='&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'), Button(description=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LorenzPlotter().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=width>\n",
    "\n",
    "#### 4. Text Generation\n",
    "\n",
    "This is a real life example for sequence prediction task. Given a beginning of a sentence, the model will try to write the remaining part. We can generate long paragraphs of articles using this. To generate nice and meaningful text we may need a very large model. Here, we only use a very small model for demonstration.\n",
    "\n",
    "There are two types of models:\n",
    "- Character : Character level model, the model will generate single character each step.\n",
    "- Word : Word level model, the model generate a word each step.\n",
    "\n",
    "<div>\n",
    "\n",
    "<style>\n",
    "div.width {\n",
    "\n",
    "    margin:auto;\n",
    "    max-width: 1000px;\n",
    "}\n",
    "</style>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d2a01ff43594ea99317c16d040c59d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(HTML(value=' <font size=\"+0.4\">Model Type: </font>'), ToggleButtons(options=('Ch…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TextGenerator().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=width>\n",
    "\n",
    "### 2. Basic Architectures for seq2seq modelling\n",
    "\n",
    "Next let's look at some basic architectures for seq2seq modelling, we will began with recurrent neural work (RNN), which is one of the most simple architectures.\n",
    "</div>\n",
    "\n",
    "<div class=width>\n",
    "\n",
    "#### 1.Recurrent neural networks (RNN)\n",
    "\n",
    "Recurrent neural network is the most basic sequence to sequence model. The dynamic can be written as \n",
    "$$\\begin{align*}\n",
    "h_{t+1} &= \\sigma(Wh_{t} + Ux_{t} + b)\\\\\n",
    "o_{t+1} &= c^\\top h_t.\n",
    "\\end{align*}$$ \n",
    "Where $h$ is called the hidden state. Note that this architecture is causal such that the output $o_t$ at time $t$ only depends on inputs up to $t$. \n",
    " \n",
    "<p align=\"center\">\n",
    "<img src=\"resources/assets/rnn.png\" alt=\"drawing\" width=\"500\" >\n",
    "</p>\n",
    "\n",
    "Based on the structure above we can have input output pairs having same length, which is typical supervised learning tasks. We can also feed the output $o_t$ as the input $x_{t+1}$, which forms an autoregressive structure and are usually applied to time series prediction  or sequence generation. \n",
    "\n",
    "In the following demo implementation, the model takes a input with size **(batch size, input len, input dim)**, and output having size **(batch size, input len, output dim)**.\n",
    "\n",
    "</div>\n",
    "\n",
    "<style>\n",
    "div.width {\n",
    "\n",
    "    margin:auto;\n",
    "    max-width: 1000px;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Implementation\n",
    "class RNN:\n",
    "    def __init__(self,\n",
    "                 input_dim,\n",
    "                 output_dim,\n",
    "                 hid_dim,\n",
    "                 activation=nn.Tanh()\n",
    "                ):\n",
    "        super().__init__()   \n",
    "        self.U = nn.Linear(input_dim, hid_dim)\n",
    "        self.W = nn.Linear(hid_dim,hid_dim)\n",
    "        self.c = nn.Linear(hid_dim, output_dim)\n",
    "        self.hid_dim = hid_dim\n",
    "    def forward(self, x, initial_hidden=None):\n",
    "\n",
    "        #src = [batch size, input len, input dim]\n",
    "        length = x.shape[1]\n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "        hidden = []\n",
    "        # Initial hidden state\n",
    "        if initial_hidden is None:\n",
    "            hidden.append(torch.zeros(batch_size, 1, self.hid_dim, dtype=x.dtype, device=x.device))\n",
    "        else:\n",
    "            hidden.append(initial_hidden)\n",
    "            \n",
    "        # recurrent relation\n",
    "        for i in range(length):\n",
    "            h_next = self.activation(self.W(hidden[i]) + self.U(x)[:,i:i+1,:])\n",
    "            hidden.append(h_next)\n",
    "\n",
    "        # Convert all hidden into a tensor\n",
    "        hidden = torch.cat(hidden[1:], dim=1)\n",
    "\n",
    "        # output mapping\n",
    "        out = self.c(hidden)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=width>\n",
    "\n",
    "Let's now test the model on the tasks we mentioned above. and plot the prediction against the output.\n",
    "You can find the saved model parameters inside folder: `resources/saved_models/lorenz`\n",
    "\n",
    "</div>\n",
    "\n",
    "<style>\n",
    "div.width {\n",
    "\n",
    "    margin:auto;\n",
    "    max-width: 1000px;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e9c51d037c046d5bc358eed06e5d5f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(HBox(children=(HTML(value='&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'), Button(description=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LorenzEvaluation(RNNModel, path='resources/saved_models/lorenz/rnn_1_10_128.ckpt').plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=width>\n",
    "\n",
    "A simple RNN model can learn the relationship fairly well.\n",
    "Let's also take a look the training curve.\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"resources/assets/rnn_lorenz_loss1.png\" alt=\"drawing\" width=\"600\" >\n",
    "</p>\n",
    "\n",
    "Note that there is a plateauing region where the loss nearly stops to decay. This phenomenon have been analyzed in the work\n",
    "[Approximation and Optimization Theory for Linear Continuous-Time Recurrent Neural Networks](https://www.jmlr.org/papers/volume23/21-0368/21-0368.pdf).\n",
    "The main idea is that RNNs are hard to learn targets with long memory, there will be a plateauing in the training loss, and the length of plateauing region is exponential to the memory.\n",
    "\n",
    "Let's next look at the shift sequence example. We generate a 32 step sequence and move it to the right by 8 steps. Let's first look at the train loss.\n",
    "<p align=\"center\">\n",
    "<img src=\"resources/assets/rnn_shiftseq_loss.png\" alt=\"drawing\" width=\"600\" >\n",
    "</p>\n",
    "The plateauing also occurs here. \n",
    "\n",
    "Next let's look at how the model makes the prediction. We can observe that the RNN nearly learn the relationship, except that it does not perform well at the jump near $x = \\text{Shift}=32$. This is because RNN have a smooth kernel, thus, if the input is smooth the output should also be smooth. For relationships lacking smoothness RNN may not perform well.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</div>\n",
    "\n",
    "<style>\n",
    "div.width {\n",
    "\n",
    "    margin:auto;\n",
    "    max-width: 1000px;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6694300efc394f6b94227fba5466a0a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(HBox(children=(HTML(value='&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'), Button(description=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ShiftEvaluation(RNNModel, 'resources/saved_models/shift/rnn_32_128.ckpt').plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=width>\n",
    "\n",
    "#### 2.Convolutional neural networks (CNN)\n",
    "\n",
    "CNNs are widely applied on computer vision related tasks. However, a 1D convolution can also be applied to sequence related tasks, since convolution is naturally a seq2seq mapping. To apply CNN on sequential data, people often use a dilated convolutions structure as shown in the picture below. By using small filters with dilation rate increasing exponentially, the model can finally achieve a very large filter with few parameters. For example in the following picture, the convolution filter achieve a receptive field of size 16 with only 8 parameters. This give arises a low rank structure, which have been discussed in \n",
    "[Approximation Theory of Convolutional Architectures for Time Series Modelling](http://proceedings.mlr.press/v139/jiang21d.html).\n",
    " \n",
    "<p align=\"center\">\n",
    "<img src=\"resources/assets/cnn.png\" alt=\"drawing\" width=\"500\" >\n",
    "</p>\n",
    "\n",
    "In the paper we discussed the difference between CNN and RNN structure on seq2seq modelling problems. The approximation capability of CNN is better then RNN for targets which is not smooth or have long memory. Through experiments we can also see CNN indeed perform better on certain tasks. \n",
    "\n",
    "Next let's look at the shift sequence example and lorenz system example using convolutional structures.\n",
    "For the Lorenz system task, we can see that CNN performs much better then RNN as it captures the pattern very well. It also have a smoother training curve.\n",
    "\n",
    "The CNN model have about 40K parameters while the RNN model have around 791K parameters. Even though the RNN have much more parameters then a CNN, the performance may not be better.\n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"resources/assets/tcn_lorenz_loss1.png\" alt=\"drawing\" width=\"600\" >\n",
    "</p>\n",
    "\n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "<style>\n",
    "div.width {\n",
    "\n",
    "    margin:auto;\n",
    "    max-width: 1000px;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a3da5f1a4aa4ba5a1ce4644e0da8feb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(HBox(children=(HTML(value='&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'), Button(description=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LorenzEvaluation(TCNModel, path='resources/saved_models/lorenz/tcn_1_10_128.ckpt').plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=width>\n",
    "\n",
    "For the shift sequence example we can hardly tell the difference from the plot. Shifting a sequence is actually a convolution operation thus the CNN is able to represent it exactly. The training curve is shown in the following image.\n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"resources/assets/tcn_shift_loss.png\" alt=\"drawing\" width=\"600\" >\n",
    "</p>\n",
    "\n",
    "</div>\n",
    "\n",
    "<style>\n",
    "div.width {\n",
    "\n",
    "    margin:auto;\n",
    "    max-width: 1000px;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fb6986f1f6a4d6680c2b65d351a9408",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(HBox(children=(HTML(value='&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'), Button(description=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ShiftEvaluation(TCNModel, 'resources/saved_models/shift/tcn_32_128.ckpt').plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<html>\n",
    "<div class=width>\n",
    "\n",
    "#### 3. Transformer\n",
    "The Transformer architecture is first introduced in [Attention is All You Need](https://arxiv.org/abs/1706.03762) paper and then become very popular for natural language processing (NLP) problems. \n",
    "    <div class=\"container\">\n",
    "      <div class=\"image\">\n",
    "        <img src=\"resources/assets/transformer.png\" alt=\"drawing\" width=\"300\" >\n",
    "      </div>\n",
    "      <div class=\"text\">\n",
    "        The transformer encoder block is show in the left figure. As the paper name Attention is All You Need indicated, the most important part in the architecture is the multi head attention block. It can be written as \n",
    "      $$\\begin{align*}\n",
    "           \\text{Atten$(x)=$softmax}(x^\\top W_Q^\\top W_K x) W_V x = A(x) x.\n",
    "        \\end{align*}$$ This can be considered as a linear transformation on the input $x$, while the matrix $A(x)$ depends on $x$ itself.\n",
    "        $A(x)$ is usually called the attention matrix, it have the property that each row is positive and summed to $1$. This means that each output at time $t$\n",
    "        $$\\begin{align*}\n",
    "           y(t) = \\sum_s [A(x)]_s \\, x(s)\n",
    "        \\end{align*}$$\n",
    "        is actually a weighted sum of all the input $x$. Sometimes for a specific $s^*$ $[A(x)]_s^* \\,$ will close to $1$, this means that the output $y(t)$ mostly depends on the $x(s^*)$. Thus, in practice people usually use attention to visualize relations between input and output.\n",
    "      </div>\n",
    "    </div>\n",
    "\n",
    "Next let's again look at the previous two experiments. \n",
    "</div>\n",
    "</html>\n",
    "\n",
    "<style>\n",
    "  div.width {\n",
    "\n",
    "    margin:auto;\n",
    "    max-width: 1000px;\n",
    "}\n",
    ".container {\n",
    "  display: flex;\n",
    "  align-items: top;\n",
    "  justify-content: center\n",
    "}\n",
    "\n",
    "img {\n",
    "  max-width: 100%\n",
    "}\n",
    "\n",
    ".image {\n",
    "  flex-basis: 40%\n",
    "}\n",
    "\n",
    ".text {\n",
    "  font-size: 20px;\n",
    "  padding-left: 20px;\n",
    "  padding-top: 20px;\n",
    "}\n",
    "</style>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f56e8ac6b9e74253920d24b118ff01ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(HBox(children=(HTML(value='&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'), Button(description=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ShiftEvaluation(TransformerModel, 'resources/saved_models/shift/transformer_32_128.ckpt').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "892d779e86cb4bb9a72a081240003e83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(HBox(children=(HTML(value='&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'), Button(description=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LorenzEvaluation(TransformerModel, 'resources/saved_models/lorenz/transformer_1_10_128.ckpt').plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=width>\n",
    "As we seen from the results, transformer can learn both pattern quite well. However, we also note that transformer produces a fluctuate prediction, which looks like a piecewise linear function. The reason why this happens is a interesting and worth further investigation.\n",
    "</div>\n",
    "\n",
    "\n",
    "<style>\n",
    "div.width {\n",
    "\n",
    "    margin:auto;\n",
    "    max-width: 1000px;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8ce0e8490cf730150a424e5807f7fde0b91ecc24faf3dcab8fe4b13f6f1ae3a5"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('env1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
